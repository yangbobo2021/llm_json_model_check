<pre>\n
model: Qwen/Qwen1.5-72B-Chat
openai error: An error occurred during streaming
LLM server error: Error code: 400 - {'error': {'message': 'Qwen/Qwen1.5-72B-Chat is not supported for JSON mode/function calling', 'type': 'invalid_request_error', 'param': None, 'code': 'constraints_model'}} for model: Qwen/Qwen1.5-72B-Chat
[False, False, False, False, False]
</pre>
